{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "torch.manual_seed(4321)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCIDataset(Dataset):\n",
    "    _data_files: List[str]\n",
    "    _data_loaded: bool = False\n",
    "\n",
    "    _data: np.ndarray\n",
    "    _labels: np.ndarray\n",
    "\n",
    "    def __init__(\n",
    "        self, data_files: List[str] = [\"S4b_train.npz\", \"X11b_train.npz\"]\n",
    "    ):\n",
    "        super(BCIDataset, self).__init__()\n",
    "        for file in data_files:\n",
    "            if not os.path.exists(file):\n",
    "                raise FileNotFoundError(f\"The data file {file} does not exist.\")\n",
    "        \n",
    "        self._data_files = data_files\n",
    "\n",
    "    def __len__(self):\n",
    "        # lazy loading\n",
    "        if not self._data_loaded:\n",
    "            self._load_data()\n",
    "\n",
    "        return self._labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor]:\n",
    "        # lazy loading\n",
    "        if not self._data_loaded:\n",
    "            self._load_data()\n",
    "\n",
    "        return torch.from_numpy(self._data[index]), self._labels[index]\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for file in self._data_files:\n",
    "            with np.load(file) as f:\n",
    "                data.append(f[\"signal\"])\n",
    "                labels.append(f[\"label\"])\n",
    "\n",
    "        self._data = np.concatenate(data, axis = 0)\n",
    "        self._labels = np.concatenate(labels, axis = 0)\n",
    "\n",
    "        self._data = np.expand_dims(self._data, axis=1).swapaxes(-1, -2)\n",
    "        self._labels -= 1\n",
    "\n",
    "        mask = np.where(np.isnan(self._data))\n",
    "        self._data[mask] = np.nanmean(self._data)\n",
    "\n",
    "        self._data_loaded = True\n",
    "\n",
    "train_dataset = BCIDataset(data_files = [\"S4b_train.npz\", \"X11b_train.npz\"])\n",
    "test_dataset = BCIDataset(data_files = [\"S4b_test.npz\", \"X11b_test.npz\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    _activation_dict = {\n",
    "        \"ELU\": lambda: nn.ELU(alpha = 1.0),\n",
    "        \"ReLU\": lambda: nn.ReLU(),\n",
    "        \"LeakyReLU\": lambda: nn.LeakyReLU(negative_slope = 0.01)\n",
    "    }\n",
    "    _activation_name: str\n",
    "\n",
    "    def __init__(self, activation: str):\n",
    "        super(Model, self).__init__()\n",
    "        if activation not in self._activation_dict:\n",
    "            raise NotImplementedError(f\"The activation function {activation} is not implemented.\")\n",
    "\n",
    "        self.activation = None\n",
    "        self.activation_name = activation\n",
    "\n",
    "    @property\n",
    "    def activation(self) -> nn.Module:\n",
    "        return self._activation_dict[self._activation_name]()\n",
    "\n",
    "    @activation.setter\n",
    "    def activation(self, _):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def activation_name(self) -> str:\n",
    "        return self._activation_name\n",
    "\n",
    "    @activation_name.setter\n",
    "    def activation_name(self, name: str):\n",
    "        self._activation_name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEGNet\n",
    "\n",
    "#### Architecture\n",
    "![EEGNet](assets/EEGNet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGNet(\n",
      "  (first_conv): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (depthwise_conv): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(2, 1), stride=(1, 1), groups=16, bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "    (4): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (separable_conv): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "    (4): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (classfier): Sequential(\n",
      "    (0): Linear(in_features=736, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EEGNet(Model):\n",
    "    first_conv: nn.Sequential\n",
    "    depthwise_conv: nn.Sequential\n",
    "    separable_conv: nn.Sequential\n",
    "    classfier: nn.Sequential\n",
    "\n",
    "    def __init__(self, activation: str = \"ELU\"):\n",
    "        super(EEGNet, self).__init__(activation)\n",
    "\n",
    "        self.first_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = (1, 51), stride = (1, 1), padding = (0, 25), bias = False),\n",
    "            nn.BatchNorm2d(16, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "        )\n",
    "        self.depthwise_conv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size = (2, 1), stride = (1, 1), groups = 16, bias = False),\n",
    "            nn.BatchNorm2d(32, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "            self.activation,\n",
    "            nn.AvgPool2d(kernel_size = (1, 4), stride = (1, 4), padding = 0),\n",
    "            nn.Dropout(p = 0.25)\n",
    "        )\n",
    "        # input: batch, 32, 2, 188\n",
    "        self.separable_conv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size = (1, 15), stride = (1, 1), padding = (0, 7), bias = False),\n",
    "            nn.BatchNorm2d(32, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "            self.activation,\n",
    "            nn.AvgPool2d(kernel_size = (1, 8), stride = (1, 8), padding = 0),\n",
    "            nn.Dropout(p = 0.25)\n",
    "        )\n",
    "        self.classfier = nn.Sequential(\n",
    "            nn.Linear(736, 2, bias = True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.separable_conv(x)\n",
    "        return self.classfier(x)\n",
    "\n",
    "network = EEGNet(activation = \"ELU\")\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepConvNet\n",
    "\n",
    "#### Architecture\n",
    "> Parameters: C = 2, T = 750, N = 2\n",
    "\n",
    "![DeepConvNet](assets/DeepConvNet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepConvNet(\n",
      "  (first_conv_block): Sequential(\n",
      "    (0): Conv2d(1, 25, kernel_size=(1, 5), stride=(1, 1))\n",
      "    (1): Conv2d(25, 25, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (2): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv_blocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(25, 50, kernel_size=(1, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(50, 100, kernel_size=(1, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(100, 200, kernel_size=(1, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classfier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8400, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DeepConvNet(Model):\n",
    "    first_conv_block: nn.Sequential\n",
    "    conv_blocks: nn.ModuleList\n",
    "    classfier: nn.Sequential\n",
    "\n",
    "    def __init__(self, activation: str = \"ELU\"):\n",
    "        super(DeepConvNet, self).__init__(activation)\n",
    "\n",
    "        in_channels = 1\n",
    "        out_channels = 25\n",
    "        self.first_conv_block = nn.Sequential(\n",
    "            # H = 2, W = 750\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = (1, 5), stride = (1, 1), bias = True),\n",
    "            # H = 2, W = 750 - 5 + 1 = 746\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size = (2, 1), stride = (1, 1), bias = True),\n",
    "            # H = 1, W = 746\n",
    "            nn.BatchNorm2d(out_channels, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "            self.activation,\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            # H = 1, W = 373\n",
    "            nn.Dropout(p = 0.5)\n",
    "        )\n",
    "\n",
    "        kernels = (50, 100, 200)\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        for kernel in kernels:\n",
    "            in_channels = out_channels\n",
    "            out_channels = kernel\n",
    "            self.conv_blocks.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size = (1, 5), stride = (1, 1), bias = True),\n",
    "                nn.BatchNorm2d(out_channels, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d((1, 2)),\n",
    "                nn.Dropout(p = 0.5)\n",
    "            ))\n",
    "        # conv_blocks[0]: H = 1, W = (373 - 5 + 1) / 2 = 183 (floor)\n",
    "        # conv_blocks[1]: H = 1, W = (183 - 5 + 1) / 2 = 89 (floor)\n",
    "        # conv_blocks[2]: H = 1, W = (89 - 5 + 1) / 2 = 42 (floor)\n",
    "\n",
    "        self.classfier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Batch_Size, 200 * 1 * 42 = 8400\n",
    "            nn.Linear(8400, 2, bias = True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_conv_block(x)\n",
    "        x = self.conv_blocks(x)\n",
    "        return self.classfier(x)\n",
    "\n",
    "network = DeepConvNet(activation = \"ELU\")\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class Trainer:\n",
    "    _models: List[Model]\n",
    "    _optimizer: torch.optim.Optimizer\n",
    "    _loss: nn.Module\n",
    "    _train_dataloader: DataLoader\n",
    "    _test_dataloader: DataLoader\n",
    "    _epoch_size: int\n",
    "\n",
    "    _accuracy_history: Dict[str, List[float]]\n",
    "    _highest_accuracy_dict: Dict[str, float]\n",
    "    _loss_history: Dict[str, List[float]]\n",
    "\n",
    "    def __init__(\n",
    "        self, models: List[Model], optimizer: torch.optim.Optimizer, loss: nn.Module, train_dataloader: DataLoader, test_dataloader: DataLoader, epoch_size: int = 300\n",
    "    ):\n",
    "        self._models = models\n",
    "        self._optimizer = optimizer\n",
    "        self._loss = loss\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._test_dataloader = test_dataloader\n",
    "        self._epoch_size = epoch_size\n",
    "\n",
    "    def _calculate_accuracy(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "        return torch.mean(y_pred == y_true)\n",
    "\n",
    "    def show_loss(self):\n",
    "        epochs = list(range(1, self._epoch_size + 1))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(\"train loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        for model, loss_history in self._loss_history.items():\n",
    "            plt.plot(epochs, loss_history, label = model)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def show_accuracy_figure(self):\n",
    "        epochs = list(range(1, self._epoch_size + 1))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(f\"Activation function comparison ({self._models[0]._get_name()})\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy(%)\")\n",
    "        plt.ylim(top = 100)\n",
    "        for name, accuracy_history in self._accuracy_history.items():\n",
    "            accuracy_history = np.array(accuracy_history) * 100\n",
    "            plt.plot(epochs, accuracy_history, label = name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def show_accuracy_table(self):\n",
    "        columns = [model.activation_name for model in self._models]\n",
    "        rows = [self._models[0]._get_name()]\n",
    "        cell_text = [self._highest_accuracy_dict[model.activation_name] for model in self._models]\n",
    "\n",
    "        plt.table(cellText = cell_text, rowLabels = rows, colLabels = columns)\n",
    "        plt.show()\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def test(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "LEARNING_RATE: float = 1e-2\n",
    "model = EEGNet(activation = \"ELU\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCH_SIZE: int = 300\n",
    "EEGNet_trainer = Trainer(model, optimizer, loss, train_dataloader, test_dataloader, epoch_size = EPOCH_SIZE)\n",
    "EEGNet_trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DP2022Summer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1daeb12ce1c2b9107a007b93cc8d47f32e23b47396c877a51898640c6e188db1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
