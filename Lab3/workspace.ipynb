{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Any, Dict\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as torch_models\n",
    "from torchvision.io import read_image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def init_seed():\n",
    "    torch.manual_seed(4321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    _root_dir: str\n",
    "    _image_names: np.ndarray\n",
    "    _labels: np.ndarray\n",
    "\n",
    "    def __init__(\n",
    "        self, root_dir: str, image_csv: str, label_csv: str\n",
    "    ):\n",
    "        super(RetinopathyDataset, self).__init__()\n",
    "        if not os.path.exists(image_csv):\n",
    "            raise FileNotFoundError(f\"The csv file {image_csv} does not exist.\")\n",
    "        if not os.path.exists(label_csv):\n",
    "            raise FileNotFoundError(f\"The csv file {label_csv} does not exist.\")\n",
    "        if not os.path.exists(root_dir):\n",
    "            raise FileNotFoundError(f\"The folder {root_dir} does not exist.\")\n",
    "\n",
    "        self._root_dir = root_dir\n",
    "        self._image_names = np.squeeze(pd.read_csv(image_csv).values)\n",
    "        self._labels = np.squeeze(pd.read_csv(label_csv).values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._image_names.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor]:\n",
    "        \"\"\"something you should implement here\n",
    "            step1. Get the image path from 'self.img_name' and load it.\n",
    "                hint : path = root + self.img_name[index] + '.jpeg'\n",
    "\n",
    "            step2. Get the ground truth label from self.label\n",
    "\n",
    "            step3. Transform the .jpeg rgb images during the training phase, such as resizing, random flipping, \n",
    "                rotation, cropping, normalization etc. But at the beginning, I suggest you follow the hints. \n",
    "\n",
    "                In the testing phase, if you have a normalization process during the training phase, you only need \n",
    "                to normalize the data. \n",
    "\n",
    "                hints : Convert the pixel value to [0, 1]\n",
    "                        Transpose the image shape from [H, W, C] to [C, H, W]\n",
    "\n",
    "            step4. Return processed image and label\n",
    "        \"\"\"\n",
    "        image = read_image(self._root_dir + \"/\" + self._image_names[index] + \".jpeg\") / 255\n",
    "        return image, self._labels[index]\n",
    "\n",
    "train_dataset = RetinopathyDataset(root_dir = \"data\", image_csv = \"train_img.csv\", label_csv = \"train_label.csv\")\n",
    "test_dataset = RetinopathyDataset(root_dir = \"data\", image_csv = \"test_img.csv\", label_csv = \"test_label.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    model: nn.Module\n",
    "    def __init__(self, out_features, pretrained = True, feature_extracting = False):\n",
    "        super(ResNet18, self).__init__()\n",
    "\n",
    "        self.model = torch_models.resnet18(weights = torch_models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        # freeze pretrained layers\n",
    "        if pretrained and feature_extracting:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    model: nn.Module\n",
    "    def __init__(self, out_features, pretrained = True, feature_extracting = False):\n",
    "        super(ResNet50, self).__init__()\n",
    "\n",
    "        self.model = torch_models.resnet50(weights = torch_models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        # freeze pretrained layers\n",
    "        if pretrained and feature_extracting:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    _device: str\n",
    "    _criterion: nn.Module\n",
    "    _train_dataloader: DataLoader\n",
    "    _test_dataloader: DataLoader\n",
    "\n",
    "    _models_metrics: Dict[str, Dict[str, Any]]\n",
    "\n",
    "    def __init__(\n",
    "        self, criterion: nn.Module, train_dataloader: DataLoader, test_dataloader: DataLoader\n",
    "    ):\n",
    "        self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self._criterion = criterion\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "        self._models_metrics = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_accuracy(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "        return torch.sum(torch.argmax(y_pred, dim = 1) == y_true, dtype = torch.int).item()\n",
    "\n",
    "    def _show_loss(self, epoch_size: int):\n",
    "        epochs = list(range(1, epoch_size + 1))\n",
    "        accuracy_histories = {name: metrics[\"loss_history\"] for name, metrics in self._models_metrics.items()}\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(\"Train loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        for name, loss_history in accuracy_histories.items():\n",
    "            train_loss_list = loss_history[\"train\"]\n",
    "            test_loss_list = loss_history[\"test\"]\n",
    "            plt.plot(epochs, train_loss_list, label = f\"{name}_train\")\n",
    "            plt.plot(epochs, test_loss_list, label = f\"{name}_test\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _show_accuracy(self, epoch_size: int):\n",
    "        epochs = list(range(1, epoch_size + 1))\n",
    "        accuracy_histories = {name: metrics[\"accuracy_history\"] for name, metrics in self._models_metrics.items()}\n",
    "        best_test_accuracy_dict = {name: metrics[\"best_test_accuracy\"] for name, metrics in self._models_metrics.items()}\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(f\"Activation function comparison\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy(%)\")\n",
    "        for name, accuracy_history in accuracy_histories.items():\n",
    "            train_accuracy_list = accuracy_history[\"train\"]\n",
    "            test_accuracy_list = accuracy_history[\"test\"]\n",
    "            plt.plot(epochs, np.array(train_accuracy_list) * 100, label = f\"{name}_train\")\n",
    "            plt.plot(epochs, np.array(test_accuracy_list) * 100, label = f\"{name}_test\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        for name, accuracy in best_test_accuracy_dict.items():\n",
    "            print(f\"{name}'s best accuracy: {accuracy}\")\n",
    "\n",
    "    def _save_weights(self, folder_path: str):\n",
    "        for name, metrics in self._models_metrics.items():\n",
    "            weights = metrics[\"best_model_weights\"]\n",
    "            epoch = metrics[\"best_epoch\"]\n",
    "            torch.save(weights, folder_path + \"/\" + f\"{name}_epoch_{epoch}.pth\")\n",
    "\n",
    "    def _add_metrics(self, models: Dict[str, nn.Module]):\n",
    "        for name, model in models.items():\n",
    "            tmp = {\n",
    "                \"accuracy_history\": {\n",
    "                    \"train\": [],\n",
    "                    \"test\": []\n",
    "                },\n",
    "                \"loss_history\": {\n",
    "                    \"train\": [],\n",
    "                    \"test\": []\n",
    "                },\n",
    "                \"best_epoch\": -1,\n",
    "                \"best_test_accuracy\": 0,\n",
    "                \"best_model_weights\": None\n",
    "            }\n",
    "            self._models_metrics[name] = tmp\n",
    "\n",
    "    def clear_metrics(self, model_name: str):\n",
    "        del self._models_metrics[model_name]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _test(self, epoch: int, model_name: str, model: nn.Module):\n",
    "        model_metrics = self._models_metrics[model_name]\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        sample_size = len(self._test_dataloader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        for x, y in self._test_dataloader:\n",
    "            x, y = x.to(self._device), y.to(self._device)\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss += self._criterion(y_pred, y).item() * x.size(0)\n",
    "            accuracy += self._calculate_accuracy(y_pred.cpu(), y.cpu())\n",
    "\n",
    "        loss /= sample_size\n",
    "        accuracy /= sample_size\n",
    "        model_metrics[\"loss_history\"][\"test\"].append(loss)\n",
    "        model_metrics[\"accuracy_history\"][\"test\"].append(accuracy)\n",
    "        if accuracy > model_metrics[\"best_test_accuracy\"]:\n",
    "            model_metrics[\"best_epoch\"] = epoch\n",
    "            model_metrics[\"best_model_weights\"] = deepcopy(model.state_dict())\n",
    "            model_metrics[\"best_test_accuracy\"] = accuracy\n",
    "        return loss, accuracy\n",
    "\n",
    "    def train(self, models: Dict[str, nn.Module], optimizer_fn, epoch_size: int, early_stop: bool = False, save_weights: bool = False, folder_path: str = \".\"):\n",
    "        self._add_metrics(models)\n",
    "        for name, model in models.items():\n",
    "            print(f\"Training {name} model...\")\n",
    "            model.to(self._device)\n",
    "            optimizer = optimizer_fn(model.parameters())\n",
    "\n",
    "            loss_list = []\n",
    "            accuracy_list = []\n",
    "            sample_size = len(self._train_dataloader.dataset)\n",
    "            model_metrics = self._models_metrics[name]\n",
    "\n",
    "            model.train()\n",
    "            for epoch in range(1, epoch_size + 1):\n",
    "                train_loss = 0\n",
    "                train_accuracy = 0\n",
    "\n",
    "                for x, y in self._train_dataloader:\n",
    "                    x, y = x.to(self._device), y.to(self._device)\n",
    "\n",
    "                    # predict\n",
    "                    y_pred = model(x)\n",
    "                    loss = self._criterion(y_pred, y)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    train_loss += loss.item() * x.size(0)\n",
    "                    train_accuracy += self._calculate_accuracy(y_pred.detach().cpu(), y.detach().cpu())\n",
    "\n",
    "                test_loss, test_accuracy = self._test(epoch, name, model)\n",
    "\n",
    "                train_loss /= sample_size\n",
    "                train_accuracy /= sample_size\n",
    "                if epoch % 100 == 0:\n",
    "                    print(f\"epoch: {epoch}, train loss: {train_loss}, train accuracy: {train_accuracy}, test loss: {test_loss}, test accuracy: {test_accuracy}\")\n",
    "\n",
    "                loss_list.append(train_loss)\n",
    "                accuracy_list.append(train_accuracy)\n",
    "\n",
    "            model_metrics[\"loss_history\"][\"train\"] = loss_list\n",
    "            model_metrics[\"accuracy_history\"][\"train\"] = accuracy_list\n",
    "            models[name] = model.cpu()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        self._show_loss(epoch_size)\n",
    "        self._show_accuracy(epoch_size)\n",
    "        if save_weights:\n",
    "            self._save_weights(folder_path)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18_pretrained model...\n"
     ]
    }
   ],
   "source": [
    "init_seed()\n",
    "\n",
    "BATCH_SIZE: int = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Prepare models\n",
    "# make sure the model is reproducible\n",
    "NUM_CLASSES: int = 5\n",
    "models = {}\n",
    "init_seed()\n",
    "models[\"ResNet18_pretrained\"] = ResNet18(NUM_CLASSES, pretrained = True, feature_extracting = False)\n",
    "# init_seed()\n",
    "# models[\"ResNet18\"] = ResNet18(NUM_CLASSES, pretrained = False)\n",
    "\n",
    "LEARNING_RATE: float = 1e-3\n",
    "optimizer_fn = lambda params: torch.optim.SGD(params, lr = LEARNING_RATE, momentum = 0.9, weight_decay = 5e-4)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCH_SIZE: int = 30\n",
    "EEGNet_trainer = Trainer(loss, train_dataloader, test_dataloader)\n",
    "EEGNet_trainer.train(models, optimizer_fn, EPOCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed()\n",
    "\n",
    "BATCH_SIZE: int = 512\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "LEARNING_RATE: float = 1e-3\n",
    "NUM_CLASSES: int = 5\n",
    "models = {\n",
    "    \"ResNet50_pretrained\": ResNet50(NUM_CLASSES),\n",
    "    \"ResNet50\": ResNet50(NUM_CLASSES, pretrained = False),\n",
    "}\n",
    "optimizer_fn = lambda params: torch.optim.SGD(params, lr = LEARNING_RATE, momentum = 0.9, weight_decay = 5e-4)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCH_SIZE: int = 100\n",
    "EEGNet_trainer = Trainer(loss, train_dataloader, test_dataloader)\n",
    "EEGNet_trainer.train(models, optimizer_fn, EPOCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DP2022Summer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1daeb12ce1c2b9107a007b93cc8d47f32e23b47396c877a51898640c6e188db1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
